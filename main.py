import pandas as pd
import os
import re
from datetime import datetime
import time
import pytz
import requests


def get_all_tag(website_info_data):
    all_tag = []
    all_tag_info_data = []
    # éå†æ•°æ®,è·å–æ‰€æœ‰çš„tag
    for website_info_index, website_info_row in website_info_data.iterrows():
        tag_list = website_info_row["Tag"].split(";")
        pure_tag_list = []
        for tag in tag_list:
            pure_tag = tag.strip()
            if pure_tag != "":
                pure_tag_list.append(pure_tag)
                if pure_tag not in all_tag:
                    all_tag.append(pure_tag)
                    all_tag_info_data.append([])
        print("pure_tag_list", pure_tag_list)
        print(
            "tag==>>",
            website_info_index,
            website_info_row["Tag"],
            "pure_tag_list==>>",
            pure_tag_list,
        )

    # éå†æ‰€æœ‰æ•°æ®,å°†æ•°æ®æ”¾åˆ°all_tag_info_data ä¸­
    for website_info_index, website_info_row in website_info_data.iterrows():
        tag_list = website_info_row["Tag"].split(";")
        for tag in tag_list:
            pure_tag = tag.strip()
            if pure_tag != "":
                all_tag_info_data[all_tag.index(pure_tag)].append(website_info_row)

    print("all_tag", all_tag, "all_tag_info_data", all_tag_info_data)
    return {"all_tag": all_tag, "all_tag_info_data": all_tag_info_data}


def short_url(url):
    result = ""
    url = url.lstrip("http://")
    url = url.lstrip("https://")
    url = url.lstrip("www.")
    url = url.rstrip("/")

    if len(url) > 30:
        result = url[0:30] + "..."
    else:
        result = url
    return result


def replaceTemplate(template, reInfo, data):

    reResult = re.findall(reInfo, template)
    new_read_me = template.replace(reResult[0], data)
    return new_read_me


def create_tag_table_html(tag_name, tag_info_data):
    print("==create_tag_table_html", tag_name)
    website_info_html = "<table>"
    website_info_html = (
        website_info_html
        + "<tr>"
        + "<td width='400'>"
        + "<span>(ã¥ï½¡â—•â€¿â€¿â—•ï½¡)ã¥</span><br/><span>Name</span>"
        + "</td>"
        + "<td>"
        + "<span> (â—ï¾ŸÏ‰ï¾Ÿâ—)</span><br/><span>Description</span>"
        + "</td>"
        + "</tr>"
    )
    for info_data in tag_info_data:
        print(
            "==>>",
            {
                "Name": info_data["Name"],
                "Url": info_data["Url"],
                "Description": info_data["Description"],
            },
        )
        website_info_html = (
            website_info_html
            + "<tr>"
            + "<td>"
            + info_data["Name"]
            + "</td>"
            + "<td>"
            + info_data["Description"]
            + "</td>"
            + "</tr>"
        )

    website_info_html = website_info_html + "</table>"

    return website_info_html


def main():
    # è¯»å–csvæ–‡ä»¶
    website_info_data = pd.read_csv("./website_info.csv")
    # åè½¬æ•°æ®,ä¿è¯æœ€æ–°çš„æ•°æ®åœ¨æœ€å‰é¢
    website_info_data = website_info_data.reindex(index=website_info_data.index[::-1])
    print(website_info_data)
    # éå†æ•°æ®
    for website_info_index, website_info_row in website_info_data.iterrows():
        print("=start=>>", website_info_index, website_info_row["Url"])
        # æ£€æµ‹ç½‘ç«™å¯ç”¨æ€§,è®°å½•è¯·æ±‚æ—¶é—´,å®Œæˆæ•°æ®æ‹¼æ¥
        try:
            # æ£€æµ‹ç½‘ç«™æ˜¯å¦æ­£å¸¸
            website_info_row_url_result = requests.get(
                website_info_row["Url"], timeout=5
            )
            total_ms = str(
                int(website_info_row_url_result.elapsed.total_seconds() * 1000)
            )
            # å“åº”ç ä¸º2å¼€å¤´,æ ‡æ³¨ç»¿è‰²,å¦åˆ™æ ‡æ³¨çº¢è‰²
            if website_info_row_url_result.status_code:
                website_info_row["Name"] = (
                    "<span style='font-weight: 600'>"
                    + website_info_row["Name"]
                    + "</span>"
                    + "<span>"
                    + (
                        " ğŸŸ¢ " + total_ms + "ms"
                        if str(website_info_row_url_result.status_code).startswith("2")
                        else " ğŸ”´"
                    )
                    + "</span><br/>"
                )
        # æ— æ³•å“åº”ï¼Œæ ‡æ³¨çº¢è‰²
        except Exception as e:
            print("error==", e)
            website_info_row["Name"] = (
                "<span style='font-weight: 600'>"
                + website_info_row["Name"]
                + " ğŸ”´"
                + "</span><br/>"
            )
        finally:
            website_info_row["Name"] = (
                "<span>"
                + website_info_row["Name"]
                + "</span>"
                + "<a href='"
                + website_info_row["Url"]
                + "'>"
                + (short_url(website_info_row["Url"]))
                + "</a>"
            )
            print("finish", website_info_row["Url"], website_info_row["Name"])
    # å®Œæˆtableæ•°æ®æ‹¼æ¥
    website_info_html = "<table>"
    website_info_html = (
        website_info_html
        + "<tr>"
        + "<td width='400'>"
        + "<span>(ã¥ï½¡â—•â€¿â€¿â—•ï½¡)ã¥</span><br/><span>Name</span>"
        + "</td>"
        + "<td>"
        + "<span> (â—ï¾ŸÏ‰ï¾Ÿâ—)</span><br/><span>Description</span>"
        + "</td>"
        + "<td width='300'>"
        + "<span> ï¸¿(ï¿£ï¸¶ï¿£)ï¸¿</span><br/><span>Tag</span>"
        + "</td>"
        + "</tr>"
    )
    for website_info_index, website_info_row in website_info_data.iterrows():
        website_info_html = (
            website_info_html
            + "<tr>"
            + "<td>"
            + website_info_row["Name"]
            + "</td>"
            + "<td>"
            + website_info_row["Description"]
            + "</td>"
            + "<td>"
            + website_info_row["Tag"]
            + "</td>"
            + "</tr>"
        )
    website_info_html = website_info_html + "</table>"
    # æ ¹æ®EditREADME.mdæ¨¡æ¿,æ›¿æ¢å ä½ç¬¦, ç”Ÿæˆæœ€ç»ˆæ•°æ®
    readme_md = ""
    with open(os.path.join(os.getcwd(), "EditREADME.md"), "r") as load_f:
        readme_md = load_f.read()
    mail_re = r"--insStart----insEnd--"
    in_datetime = datetime.fromtimestamp(
        int(time.time()), pytz.timezone("Asia/Shanghai")
    ).strftime("%Y-%m-%d %H:%M:%S")
    all_info_content = (
        "\n\n"
        + "## å¼€æºçµæ„Ÿåº“å·²æ”¶å½•"
        + str(len(website_info_data))
        + "æŸçµæ„ŸINS!"
        + "(ï½ï¿£â–½ï¿£)ï½æ›´æ–°æ—¶é—´("
        + in_datetime
        + ")\n\n"
        + website_info_html
        + "\n\n"
    )
    new_read_me = replaceTemplate(readme_md, mail_re, all_info_content)
    print("new_read_me", new_read_me)

    # ç”Ÿæˆç±»åˆ«æ•°æ®
    tag_re = r"--tagStart----tagEnd--"
    all_tag_result = get_all_tag(website_info_data)
    all_tag = all_tag_result["all_tag"]
    all_tag_info_data = all_tag_result["all_tag_info_data"]
    print("==all_tag_info_data==", all_tag_info_data)
    print("==all_tag==", all_tag)
    all_tag_content = ""

    for tag_content in all_tag:
        tag_html = create_tag_table_html(
            tag_content, all_tag_info_data[all_tag.index(tag_content)]
        )
        tag_whole_content = "## " + tag_content + "\n\n" + tag_html + "\n\n"
        all_tag_content = all_tag_content + tag_whole_content

    new_read_me = replaceTemplate(new_read_me, tag_re, all_tag_content)

    # æ·»åŠ ç´¢å¼•é”šç‚¹
    tag_index_info = ""
    for tag_index, tag_content in enumerate(all_tag):
        if tag_index != (len(all_tag) - 1):
            tag_index_info = (
                tag_index_info
                + "<a href='#"
                + tag_content
                + "'>"
                + tag_content
                + "</a>"
                + ", "
            )
        else:
            tag_index_info = (
                tag_index_info
                + "<a href='#"
                + tag_content
                + "'>"
                + tag_content
                + "</a>"
            )

    tag_index_re = r"--tagIndexInfoStart----tagIndexInfoEnd--"

    new_read_me = replaceTemplate(new_read_me, tag_index_re, tag_index_info)

    # å°†ç”Ÿæˆçš„æ•°æ®å†™å…¥README.md
    with open(os.path.join(os.getcwd(), "README.md"), "w") as load_f:
        load_f.write(new_read_me)


main()
